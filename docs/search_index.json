[["index.html", "Reproducibility in Cancer Informatics About this Course", " Reproducibility in Cancer Informatics October, 2021 About this Course This course is part of a series of courses for the Informatics Technology for Cancer Research (ITCR) called the Informatics Technology for Cancer Research Education Resource. This material was created by the ITCR Training Network (ITN) which is a collaborative effort of researchers around the United States to support cancer informatics and data science training through resources, technology, and events. This initiative is funded by the following grant: National Cancer Institute (NCI) UE5 CA254170. Our courses feature tools developed by ITCR Investigators and make it easier for principal investigators, scientists, and analysts to integrate cancer informatics into their workflows. Please see our website at www.itcrtraining.org for more information. "],["introduction.html", "Chapter 1 Introduction 1.1 Motivation 1.2 Target Audience 1.3 Curriculum", " Chapter 1 Introduction 1.1 Motivation Cancer datasets are plentiful, complicated, and hold untold amounts of information regarding cancer biology. Cancer researchers are working to apply their expertise to the analysis of these vast amounts of data but training opportunities to properly equip them in these efforts can be sparse. This includes training in reproducible data analysis methods. Data analyses are also are generally not reproducible without direct contact with the original researchers and a substantial amount of time and effort (BeaulieuJones2017 and Greene 2017). Reproducibility in cancer informatics (as with other fields) is still not monitored or incentivized despite that it is fundamental to the scientific method. Despite the lack of incentive, many researchers strive for reproducibility in their own work but often lack the skills or training to do so effectively. Equipping researchers with the skills to create reproducible data analyses increases the efficiency of everyone involved. Reproducible analyses are more likely to understood, applied, and replicated by others. This helps expedite the scientific process by helping researchers avoid false positive dead ends. Open source clarity in reproducible methods also saves researchers’ time so they don’t have to reinvent the proverbial wheel for methods that everyone in the field is already performing. This course introduces the concepts of reproducibility and replicability in the context of cancer informatics. It uses hands-on exercises to demonstrate in practical terms how to increase the reproducibility of data analyses. The course also introduces tools relevant to reproducibility including analysis notebooks, Docker images, git and GitHub. 1.2 Target Audience The course is intended for students in the biomedical sciences and researchers who use informatics tools in their research. 1.3 Curriculum The course includes a hands-on exercises for how to apply reproducible code concepts to their code. Individuals who take this course are encouraged to complete these activities as they follow along with the course material to help increase the reproducibility of their analyses. References "],["defining-reproducibility.html", "Chapter 2 Defining reproducibility 2.1 Learning Objectives 2.2 What is reproducibility 2.3 Reproducibility in daily life 2.4 Reproducibility is worth the effort! 2.5 Reproducibility exists on a continuum!", " Chapter 2 Defining reproducibility 2.1 Learning Objectives 2.2 What is reproducibility There’s been a lot of discussion about what is included in the term reproducibility and there is some discrepancy between fields. For the purposes of informatics and data analysis, a reproducible analysis is one that can be re-run by a different researcher and the same result and conclusion is found. Reproducibility is related to repeatability and replicability but it is worth taking the time parse out these terms. Perhaps you are like Ruby and have just found an interesting pattern through your data analysis! This has probably been the result of many months or years on your project and its worth celebrating! But before you get too excited, Ruby should ask herself whether she is able to re-run her own analysis and get the same results again. This is known as repeatability. Given that Ruby’s analysis is repeatable; she may feel confident now to share her preliminary results with her colleague, Avi the Associate. Whether or not someone else will be able to take Ruby’s code and data, re-run the analysis and obtain the same results is known as reproducibility. If Ruby’s results are able to be reproduced by Avi, now Avi may collect new data and use Ruby’s same analysis methods to analyze his data. Whether or not Avi’s new data and results concur with Ruby’s study’s original inferences is known as replicability. You may realize that these levels of research build on each other (like science is supposed to do). In this way, we can think of these in a hierarchy. Skipping any of these levels of research applicability can lead to unreliable results and conclusions. Science progresses when data and hypotheses are put through these levels thoroughly and sequentially. If results are not repeatable, they won’t be reproducible or replicable. Ideally all analyses and results would be reproducible without too much time effort spent; this would aid in the efficiency of research getting to the next stages and questions. But unfortunately, in practice, reproducibility is not as commonplace as we would hope. Institutions and reward systems generally do not prioritize or even measure reproducibility standards in research and training opportunities for reproducible techniques can be scarce. Reproducible research can often feel like uphill battle that is made steeper by lack of training opportunities. In this course, we hope to equip your research with the tools you need to enhance the reproducibility of your analyses so this uphill battle is less steep. 2.3 Reproducibility in daily life What does reproducibility in mean in the daily life of a researcher? Let’s say Ruby’s results are repeatable in her own hands and she excitedly tells her associate, Avi about her preliminary findings. Avi is very excited about these results as well as Ruby’s methods! Avi is also interested in Ruby’s analysis methods and results. So Ruby sends Avi the code and data she used to obtain the results. Now, whether or not Avi is able to obtain the same exact results with this same data and same analysis code will indicate if Ruby’s analysis is reproducible. Ruby may have spent a lot of time on her code and getting it to work on her computer, but whether it will successfully work on Avi’s computer is another story. Often when researchers share their analysis code it leads to a substantial amount of effort on the part of the researcher who has received the code to get it working and this often cannot be done successfully without help from the original code author (BeaulieuJones2017 and Greene 2017). Avi is encountering errors because Ruby’s code was written with Ruby’s computer and local set up in mind and she didn’t know how to make it more generally applicable. Avi is spending a lot of time just trying to re-run Ruby’s same analysis on her same data; he has yet to be able to try the code on any additional data (which will likely bring up even more errors). Avi is still struggling to work with Ruby’s code and is confused about the goals and approaches the code is taking. After struggling with Avi’s code for an untold amount of time, Avi may decide its time to email Ruby to get some clarity. Now both Avi and Ruby are confused about why this analysis isn’t nicely re-running for Avi. Their attempts to communicate about the code through email haven’t helped them clarify anything. Multiple versions of the code may have been sent back and forth between them and now things are taking a lot more time than either of them expected. Perhaps at some point Avi is able to successfully run Ruby’s code on Ruby’s same data. Just because Avi didn’t get any errors doesn’t mean that the code ran exactly the same as it did for Ruby. Lack of errors also doesn’t mean that either Ruby or Avi’s runs of the code ran with high accuracy or that the results can be trusted. Even a small difference in decimal point may indicate a more fundamental difference in how the analysis was performed and this could be due to differences in software versions, settings, or any number of items in their computing environments. 2.4 Reproducibility is worth the effort! Perhaps you’ve found yourself in a situation like Ruby and Avi; struggling to re-run code that you thought for sure was working a minute ago. In the upcoming chapters, we will discuss how to bolster your projects’ reproducibility. As you apply these reproducible techniques to your research may feel like it is taking more time to reach endpoints, but keep in mind that reproducible analyses and projects have higher upfront costs but these will absolutely pay off in the long term. Reproducibility in your analyses is not only a time saver for yourself, but also your colleagues, your field, and your future self! You might not change a single character in your code but then return to it in a a few days/months/years and find that it no longer runs! Reproducible code stands the test of time longer, making future you glad you spent the time to work on it. It’s said that your closest collaborator is you from 6 months ago but you don’t reply to email. Broman (n.d.) Many a data scientist has referred to their frustration with their past selves: Dear past-Hadley: PLEASE COMMENT YOUR CODE BETTER. Love present-Hadley — Hadley Wickham (@hadleywickham) April 7, 2016 The more you comment your code, and make it clear and readable, your future self will thank you. Reproducible code also saves your colleagues time! The more reproducible your code is, the less time all of your collaborators will need to spend troubleshooting it. The more people who use your code and need to try to fix it, the more time is wasted. This can add up to a lot of wasted researcher time and effort. But, reproducible code saves everyone exponential amounts of time and effort! It will also motivate individuals to use and cite your code and analyses in the future! 2.5 Reproducibility exists on a continuum! Incremental work on your analyses is good! You do not need to make your analyses perfect on the first try or even in a particular time frame. The first step in creating an analysis is to get it to work once! But the work does not end there. Furthermore, no analysis is or will ever be perfect in that it will not be reproducible in every single context throughout time. But somewhere toward the right of this continuum is what we will aim for. References "],["organizing-your-project.html", "Chapter 3 Organizing your project 3.1 Learning Objectives 3.2 Organizational strategies 3.3 Readings about organizational strategies for data science projects: 3.4 Get the exercise project files (or continue with the files you used in the previous chapter) 3.5 Exercise: Organize your project! 3.6 Why git and GitHub 3.7 Get the exercise project files (or continue with the files you used in the previous chapter) 3.8 Exercise: Set up a project on GitHub", " Chapter 3 Organizing your project 3.1 Learning Objectives Keeping your files organized is a skill that has a high long-term pay off. As you are in the thick of an analysis, you may underestimate how many files and terms you have floating around. But a short time later, you may return to your files and realize your organization was not as clear as you hoped. Tayo (2019) discusses four particular reasons why it is important to organize your project: Organization increases productivity. If a project is well organized, with everything placed in one directory, it makes it easier to avoid wasting time searching for project files such as datasets, codes, output files, and so on. A well-organized project helps you to keep and maintain a record of your ongoing and completed data science projects. Completed data science projects could be used for building future models. If you have to solve a similar problem in the future, you can use the same code with slight modifications. A well-organized project can easily be understood by other data science professionals when shared on platforms such as Github. Organization is yet another aspect of reproducibility that saves you and your colleagues time! 3.2 Organizational strategies There’s a lot of ways to keep your files organized, and there’s not a “one size fits all” organizational solution (Shapiro et al. 2021). In this chapter, we will discuss some generalities but as far as specifics we will point you to others’ who have written about works for them and advise that you use them as inspiration to figure out a strategy that works for you and your team. The most important aspects of your project organization scheme is that it: Is project-oriented (Bryan 2017). Follows consistent patterns. Is easy for you and others to find the files you need quickly. Minimizes the likelihood for errors (like writing over files accidentally). Is something maintainable! (Shapiro et al. 2021) 3.2.1 Tips for organizing your project: Getting more specific, here’s some ideas of how to organize your project: Make file names informative to those who don’t have knowledge of the project but avoid using spaces, quotes, or unusual characters in your filenames and folders – these only serve to make reading in files a nightmare in some programs. Number scripts in the order that they are run. Keep like-files together in their own directory: results tables with other results tables, etc. Including most importantly keeping raw data separate from processed data or other results! Put source scripts and functions in their own directory. Things that should never need to be called directly by yourself or anyone else. Put output in its own directories like results and plots. Have a central document (like a README) that describes the basic information about the analysis and how to re-run it. Make it easy on yourself, dates aren’t necessary. The computer keeps track of those. Make a central script that re-runs everything – including the creation of the folders! (more on this in a later chapter) Let’s see what these principles might look like put into practice. 3.2.1.1 Example organizational scheme Here’s an example of what this might look like: project-name/ ├── run_analysis.sh # Central script that runs everything again ├── 00-download-data.sh # The script that needs to be run first and is called by run_analysis.sh ├── 01-make-heatmap.Rmd # The script that needs to be run second and is also called by run_analysis.sh ├── README.md # The document that has the information that will orient someone to this project ├── plots/ # A folder of plots and resulting images │ └── project-name-heatmap.png ├── results/ # A folder results │ └── top_gene_results.tsv ├── raw-data/ # data files as they first arrive and **nothing** has been done to them yet. │ ├── project-name-raw.tsv │ └── project-name-metadata.tsv ├── processed-data/ # data that has been modified from the raw in some way. │ ├── project-name-quantile-normalized.tsv └── util/ # A folder of utilities that never needs to be called or touched directly unless troubleshooting something ├── plotting-functions.R └── data-wrangling-functions.R 3.3 Readings about organizational strategies for data science projects: But you don’t have to take my organizational strategy, there are lots of ideas out there. You can read through some of these articles to think about what kind of organizational strategy might work for you and your team: Jenny Bryan’s organizational strategy (Bryan and Hester, n.d.). Jenny Bryan on Project-oriented workflows(Bryan 2017). Data Carpentry mini-course about organizing projects (“Project Organization and Management for Genomics” n.d.). Andrew Severin’s strategy for organization (Severin n.d.). A BioStars thread where many individuals share their own organizational strategies (“How Do You Manage Your Files &amp; Directories for Your Projects?” n.d.). Data Carpentry course chapter about getting organized (“Introduction to the Command Line for Genomics” n.d.). 3.4 Get the exercise project files (or continue with the files you used in the previous chapter) How to get the Python project example files To get the Python project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). How to get the R project example files To get the R project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). 3.5 Exercise: Organize your project! Create a plots, results, and data folder and organize the files into their respective folders. Note that aggregated_metadata.json and LICENSE.TXT also belong in the data folder. Delete any files that say “OLD”. Keeping multiple versions of your scripts around is a recipe for mistakes and confusion. In the advanced course we will discuss how to use version control to help you track this more elegantly. After your files are organized, you are ready to move on to the next chapter and create a notebook! 3.6 Why git and GitHub git is a version control system that is a great tool for creating reproducible analyses. What is version control? Ruby here is experiencing a lack of version control and could probably benefit from using git. All of us at one point or another have created different versions of a file or document, but for analysis projects this can easily get out of hand if you don’t have a system in place. That’s where git comes in handy. There are other version control systems as well, but git is the most popular in part because it works with GitHub, an online hosting service for git controlled files. GitHub and git allow you to… 3.6.0.1 Maintain transparent analyses Open and transparent analyses are a critical part to conducting open science. GitHub allows you to conduct your analyses in an open source manner. Open science also allows others to better understand your methods and potentially borrow them for their own research, saving everyone time! 3.6.0.2 Have backups of your code and analyses at every point Life happens, sometimes you misplace a file or your computer malfunctions. If you ever lose data on your computer or need to retrieve something from an earlier version of your code, GitHub allows you to revert your losses. 3.6.0.3 Keep a documented history of your project Over the time course of a project a lot happens, especially when it comes to exploring and handling data. Sometimes the rationale behind decisions that were made around an analysis can get lost. GitHub keeps communications and tracks the changes to your files so that you don’t have to re-visit a question you already answered. 3.6.0.4 Collaborate with others 3.6.0.5 Experiment with your analysis Data science projects often lead to side analyses that could be very worth while but might be scary to venture on if you don’t have your code well version controlled. Git and GitHub allow you to venture on these side experiments without fear since your main code can be kept safe from your side venture. 3.7 Get the exercise project files (or continue with the files you used in the previous chapter) How to get the Python project example files To get the Python project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). How to get the R project example files To get the R project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). 3.8 Exercise: Set up a project on GitHub Now that we understand how useful GitHub is for creating reproducible analyses, it’s time to set ourselves up on GitHub. Git and GitHub have a whole rich world of tools and terms that can get complex quickly, but for this exercise, we will not worry about those terms and functionalities just yet, but focus on getting code up on GitHub so we are ready to collaborate and conduct open analyses! Go to Github’s main page and click Sign Up if you don’t have an account. Follow these instructions to create a repository. As a general, but not absolute rule, you will want to keep one GitHub repository for one analysis project. Name the repository something that reminds you what its related to. Choose “Public”. Check the box that says “Add a gitignore”. Check the box that says “Add a README”. Follow these instructions to add the example files you downloaded to your new repository. Congrats! You’ve started your very own project on GitHub! We encourage you to do the same with your own code and other projects! References "],["using-notebooks.html", "Chapter 4 Using Notebooks 4.1 Learning Objectives 4.2 Get the exercise project files (or continue with the files you used in the previous chapter) 4.3 Exercise: Convert code into a notebook!", " Chapter 4 Using Notebooks 4.1 Learning Objectives Notebooks are a handy way to have the code, output, and scientist’s thought process all documented in one place that is easy for others to read and follow. The notebook environment is incredibly useful for reproducible data science for a variety of reasons: 4.1.0.1 Reason 1: Notebooks allow for tracking data exploration and encourage the scientist to narrate their thought process: Each executed code cell is an attempt by the researcher to achieve something and to tease out some insight from the data set. The result is displayed immediately below the code commands, and the researcher can pause and think about the outcome. As code cells can be executed in any order, modified and re-executed as desired, deleted and copied, the notebook is a convenient environment to iteratively explore a complex problem. (Fangohr 2021) 4.1.0.2 Reason 2: Notebooks allow for easy sharing of results: Notebooks can be converted to html and pdf, and then shared as static read-only documents. This is useful to communicate and share a study with colleagues or managers. By adding sufficient explanation, the main story can be understood by the reader, even if they wouldn’t be able to write the code that is embedded in the document. (Fangohr 2021) 4.1.0.3 Reason 3: Notebooks can be re-ran as a script or developed interactively: A common pattern in science is that a computational recipe is iteratively developed in a notebook. Once this has been found and should be applied to further data sets (or other points in some parameter space), the notebook can be executed like a script, for example by submitting these scripts as batch jobs. (Fangohr 2021) This can also be handy especially if you use automation to enhance the reproducibility of your analyses (something we will talk about in the advanced part of this course). Because all of these reasons, we encourage the use of computational notebooks as a means of enhancing reproducibility. (This course itself is also written with the use of notebooks!) 4.2 Get the exercise project files (or continue with the files you used in the previous chapter) How to get the Python project example files To get the Python project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). How to get the R project example files To get the R project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). 4.3 Exercise: Convert code into a notebook! 4.3.1 Set up your IDE For this chapter, we will create notebooks from our example files code. Notebooks work best with the integrated development environment (IDE) they were created to work with. IDE’s are sets of tools that help you develop your code. They are part “point and click” and part command line and include lots of visuals that will help guide you. Set up a Python IDE 4.3.2 Install JupyterLab We advise using the conda method to install JupyterLab, because we will return to talk more about conda later on, so if you don’t have conda, you will need to install that first. To install conda using command line will look something like this in command line (but you will have to change depending on your operating system wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\ mkdir /root/.conda \\ bash Miniconda3-latest-Linux-x86_64.sh -b \\ rm -f Miniconda3-latest-Linux-x86_64.sh conda --version Then, following the instructions, install JupyterLab using this command in your command line window: conda install -c conda-forge jupyterlab If you installed JupyterLab successfully, you can run jupyter lab in your command line window and a window will open in your browser. (Note that if run this multiple times, you will need to close one of your JupyterLab browser windows, or follow their documentation to set a password). 4.3.3 Getting familiar with JupyterLab’s interface The JupyterLab interface consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list. The menu bar at the top of JupyterLab has top-level menus that expose actions available in JupyterLab with their keyboard shortcuts. The default menus are: File: actions related to files and directories Edit: actions related to editing documents and other activities View: actions that alter the appearance of JupyterLab Run: actions for running code in different activities such as notebooks and code consoles Kernel: actions for managing kernels, which are separate processes for running code Tabs: a list of the open documents and activities in the dock panel Settings: common settings and an advanced settings editor Help: a list of JupyterLab and kernel help links Set up an R IDE 4.3.4 Install RStudio Install RStudio (and install R first if you have not already). After you’ve downloaded the Rstudio installation file, double click on it and follow along with the installation prompts. Open up the RStudio application by double clicking on it. 4.3.5 Getting familiar with RStudio’s interface The RStudio environment has four main panes, each of which may have a number of tabs that display different information or functionality. (their specific location can be changed under Tools -&gt; Global Options -&gt; Pane Layout). The Editor pane is where you can write R scripts and other documents. Each tab here is its own document. This is your text editor, which will allow you to save your R code for future use. Note that change code here will not run automatically until you run it. The Console pane is where you can interactively run R code. There is also a Terminal tab here which can be used for running programs outside R on your computer The Environment pane primarily displays the variables, sometimes known as objects that are defined during a given R session, and what data or values they might hold. The Help viewer pane has several tabs all of which are pretty important: The Files tab shows the structure and contents of files and folders (also known as directories) on your computer. The Plots tab will reveal plots when you make them The Packages tab shows which installed packages have been loaded into your R session The Help tab will show the help page when you look up a function The Viewer pane will reveal compiled R Markdown documents From Shapiro et al. (2021) For even more navigation info see the RStudio IDE Cheatsheet (pdf). 4.3.6 Create a notebook! Now, in your respective IDE, we’ll turn our unreproducible scripts into notebooks. In the next chapter we will begin to dive into the code itself, but for now, we’ll get the notebook ready to go. Set up a Python notebook Start a new notebook by going to New &gt; Notebook. Then open up this chapter’s example code folder and open the make-heatmap.py file. leanbuild::include_slide(&quot;https://docs.google.com/presentation/d/1LMurysUhCjZb7DVF6KS9QmJ5NBjwWVjRn40MS9f2noE/edit#slide=id.gf8f405fdab_0_225&quot;) Now copy and paste all of the code from make-heatmap.py into a new chunk. We will later break up this large chunk of code into smaller chunks that are thematic in the next chapter. Save your Untitled.ipynb file as something that tells us what it will end up doing like make-heatmap.ipynb. Set up an R notebook Start a new notebook by going to File &gt; New Files &gt; R Notebook. Then open up this chapter’s example code folder and open the make_heatmap.R file. leanbuild::include_slide(&quot;https://docs.google.com/presentation/d/1LMurysUhCjZb7DVF6KS9QmJ5NBjwWVjRn40MS9f2noE/edit#slide=id.gfaa026a583_0_13&quot;) Practice creating a new chunk in your R notebook by clicking the Insert Chunk button on the toolbar or by pressing Cmd+Option+I. (You can also manually type out the back ticks and {}) Delete all the default text in this notebook. Now copy and paste all of the code from make_heatmap.R into a new chunk. We will later break up this large chunk of code into smaller chunks that are thematic in the next chapter. Save your untitled.Rmd into something that tells us what it will end up doing like make-heatmap.Rmd. Notice that upon saving your .Rmd file, a new file .nb.html file of the same name is created. Open that file and choose view in Browser. This shows the nicely rendered version of your analysis and snapshots whatever output existed when the .Rmd file was saved. Now that you’ve created your notebook, you are ready to start polishing that code! References "],["why-package-versions-matter.html", "Chapter 5 Why package versions matter 5.1 Get the exercise project files (or continue with the files you used in the previous chapter) 5.2 Exercise 1: Print out session info 5.3 Exercise 2: Package management", " Chapter 5 Why package versions matter As we discussed previously, sometimes two different researchers can run the same code and same data and get different results! What Ruby and Avi may not realize, is that although they may have used the same code and data, the software packages that they have on each of their computers might be very different. Even if they have the same software packages, they likely don’t have the same versions and versions can influence results! Different computing environments are not only a headache to detangle, they also can influence the reproducibility of your results (BeaulieuJones2017 and Greene 2017). There are multiple ways to deal with variations in computing environments so that your analyses will be reproducible and we will discuss a few different strategies for tackling this problem in this course and its follow up course. But for now, we will start with the least intensive to implement: session info. There are two strategies for dealing with software versions that we will use in our exercises: List the session info - The easiest (though not most comprehensive) method for handling differences in software versions is to have your code list details about your computing environment. Use package managers to handle your package for you in a way that you can share them with others. For R and Python versions of the exercises, we will be using different managers, but the foundational strategy will be the same: include a file that someone else could replicate your package set up from. For both exercises, we will download an environment file we’ve set up for you, then we will practice adding a new package to the environments we’ve provided, and add them to your new repository along with the rest of your example project files. For Python, we’ll use conda for package management and store this information in a environment.yml file. For R, we’ll use renv for package management and store this information in a renv.lock file. 5.1 Get the exercise project files (or continue with the files you used in the previous chapter) How to get the Python project example files To get the Python project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). How to get the R project example files To get the R project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). 5.2 Exercise 1: Print out session info Python version of the exercise In your scientific notebook, you’ll need to add two items. 1. Add the import session_info to a code chunk at the beginning of your notebook. 2. Add session_info.show() to a new code chunk at the very end of your notebook. 3. Save your notebook and commit it to GitHub. R version of the exercise In your Rmd file, add a chunk in the very end that looks like this: ```r sessionInfo() ``` ``` ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 20.04.2 LTS ## ## Matrix products: default ## BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.8.so ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=C ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] knitr_1.33 magrittr_1.5 hms_0.5.3 R6_2.4.1 ## [5] rlang_0.4.10 highr_0.8 stringr_1.4.0 httr_1.4.2 ## [9] tools_4.0.2 xfun_0.26 jquerylib_0.1.1 htmltools_0.5.0 ## [13] ellipsis_0.3.1 yaml_2.2.1 leanbuild_0.1.2 digest_0.6.25 ## [17] tibble_3.0.3 lifecycle_1.0.0 crayon_1.3.4 bookdown_0.24 ## [21] readr_1.4.0 vctrs_0.3.4 fs_1.5.0 curl_4.3 ## [25] evaluate_0.14 rmarkdown_2.10 stringi_1.5.3 compiler_4.0.2 ## [29] pillar_1.4.6 pkgconfig_2.0.3 ``` Now you’ll want to refresh everything before you save your notebook. In the menu, where it says “Run” click the arrow and choose “Restart R Run All Chunks” to refresh everything. Save your notebook and commit it to GitHub. 5.3 Exercise 2: Package management Python version of the exercise Download this starter conda environment.yml file by clicking on the link and place it with your example project files directory. wget https://raw.githubusercontent.com/jhudsl/reproducible-python-example/main/environment.yml ## --2021-10-27 16:21:36-- https://raw.githubusercontent.com/jhudsl/reproducible-python-example/main/environment.yml ## Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ... ## Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. ## HTTP request sent, awaiting response... 200 OK ## Length: 2657 (2.6K) [text/plain] ## Saving to: ‘environment.yml.1’ ## ## 0K .. 100% 28.1M=0s ## ## 2021-10-27 16:21:36 (28.1 MB/s) - ‘environment.yml.1’ saved [2657/2657] Navigate to your example project files directory using command line. Create your conda environment by using this file in the command. conda env create --file environment.yml Activate your conda environment using this command. conda activate reproducible-python Now start up JupyterLab again using this command: jupyter lab Follow these instructions to add the environment.yml file to the GitHub repository you created in the previous chapter. Later we will practice and discuss how to more fully utilize the features of GitHub but for now, just drag and drop it as the instructions linked describe. 5.3.1 More resources on how to use conda Install Jupyter using your own environment (Mac specific) Definitive guide to using conda R version of the exercise Go to RStudio and the Console pane: Install renv using: ## Installing package into &#39;/usr/local/lib/R/site-library&#39; ## (as &#39;lib&#39; is unspecified) Create your renv snapshot following the renv workflow process: Call renv::init() to initialize a new project-local environment with a private R library, Work in the project as normal, installing and removing new R packages as they are needed in the project, Call renv::snapshot() to save the state of the project library to the lockfile (called renv.lock), Continue working on your project, installing and updating R packages as needed. Call renv::snapshot() again to save the state of your project library if your attempts to update R packages were successful, or call renv::restore() to revert to the previous state as encoded in the lockfile if your attempts to update packages introduced some new problems. You should see an renv.lock file is now created! You will want to always include this file with your project files. This means we will want to add it to our GitHub! Follow these instructions to add your renv.lock file to the GitHub repository you created in the previous chapter. Later we will practice and discuss how to more fully utilize the features of GitHub but for now, just drag and drop it as the instructions linked describe. After you’ve added your computing environment files to your GitHub, you’re ready to continue using them with your IDE to actually work on the code in your notebook! References "],["organizing-your-project-1.html", "Chapter 6 Organizing your project 6.1 Learning Objectives 6.2 Get the exercise project files (or continue with the files you used in the previous chapter) 6.3 Exercise: Make code more durable!", " Chapter 6 Organizing your project 6.1 Learning Objectives 6.2 Get the exercise project files (or continue with the files you used in the previous chapter) How to get the Python project example files To get the Python project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). How to get the R project example files To get the R project example files, click this link. Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). 6.3 Exercise: Make code more durable! "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Lead Content Instructor(s) Candace Savonen Lecturer(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved Delivered the course in some way - video or audio Content Author(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved If any other authors besides lead instructor Content Contributor(s) (include section name/link in parentheses) - make new line if more than one section involved Wrote less than a chapter Content Editor(s)/Reviewer(s) Checked your content Content Director(s) Helped guide the content direction Content Consultants (include chapter name/link in parentheses or word “General”) - make new line if more than one chapter involved Gave high level advice on content Acknowledgments Gave small assistance to content but not to the level of consulting Production Content Publisher Ira Gooding Content Publishing Reviewer(s) Reviewed overall content and aesthetics on publishing platform Technical Course Publishing Engineer(s) Helped with the code for the technical aspects related to the specific course generation Template Publishing Engineers Candace Savonen, Carrie Wright Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (Leanbuild) John Muschelli, Candace Savonen, Carrie Wright Art and Design Illustrator(s) Created graphics for the course Figure Artist(s) Created figures/plots for course Videographer(s) Filmed videos Videography Editor(s) Edited film Audiographer(s) Recorded audio Audiography Editor(s) Edited audio recordings Funding Funder(s) Institution/individual who funded course including grant number Funding Staff Staff members who help with funding   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os Ubuntu 20.04.2 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2021-10-27 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] RSPM (R 4.0.3) ## backports 1.1.10 2020-09-15 [1] RSPM (R 4.0.2) ## bookdown 0.24 2021-09-29 [1] Github (rstudio/bookdown@88bc4ea) ## callr 3.4.4 2020-09-07 [1] RSPM (R 4.0.2) ## cli 2.0.2 2020-02-28 [1] RSPM (R 4.0.0) ## crayon 1.3.4 2017-09-16 [1] RSPM (R 4.0.0) ## desc 1.2.0 2018-05-01 [1] RSPM (R 4.0.3) ## devtools 2.3.2 2020-09-18 [1] RSPM (R 4.0.3) ## digest 0.6.25 2020-02-23 [1] RSPM (R 4.0.0) ## ellipsis 0.3.1 2020-05-15 [1] RSPM (R 4.0.3) ## evaluate 0.14 2019-05-28 [1] RSPM (R 4.0.3) ## fansi 0.4.1 2020-01-08 [1] RSPM (R 4.0.0) ## fs 1.5.0 2020-07-31 [1] RSPM (R 4.0.3) ## glue 1.4.2 2020-08-27 [1] RSPM (R 4.0.3) ## htmltools 0.5.0 2020-06-16 [1] RSPM (R 4.0.1) ## jquerylib 0.1.1 2020-04-30 [1] RSPM (R 4.0.0) ## knitr 1.33 2021-09-29 [1] Github (yihui/knitr@a1052d1) ## lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.0.2) ## magrittr 1.5 2014-11-22 [1] RSPM (R 4.0.0) ## memoise 1.1.0 2017-04-21 [1] RSPM (R 4.0.0) ## pkgbuild 1.1.0 2020-07-13 [1] RSPM (R 4.0.2) ## pkgload 1.1.0 2020-05-29 [1] RSPM (R 4.0.3) ## prettyunits 1.1.1 2020-01-24 [1] RSPM (R 4.0.3) ## processx 3.4.4 2020-09-03 [1] RSPM (R 4.0.2) ## ps 1.3.4 2020-08-11 [1] RSPM (R 4.0.2) ## purrr 0.3.4 2020-04-17 [1] RSPM (R 4.0.3) ## R6 2.4.1 2019-11-12 [1] RSPM (R 4.0.0) ## remotes 2.2.0 2020-07-21 [1] RSPM (R 4.0.3) ## rlang 0.4.10 2021-09-29 [1] Github (r-lib/rlang@f0c9be5) ## rmarkdown 2.10 2021-09-29 [1] Github (rstudio/rmarkdown@02d3c25) ## rprojroot 1.3-2 2018-01-03 [1] RSPM (R 4.0.0) ## sessioninfo 1.1.1 2018-11-05 [1] RSPM (R 4.0.3) ## stringi 1.5.3 2020-09-09 [1] RSPM (R 4.0.3) ## stringr 1.4.0 2019-02-10 [1] RSPM (R 4.0.3) ## testthat 3.0.1 2021-09-29 [1] Github (R-lib/testthat@e99155a) ## usethis 2.0.1.9000 2021-09-29 [1] Github (r-lib/usethis@3398055) ## withr 2.3.0 2020-09-22 [1] RSPM (R 4.0.2) ## xfun 0.26 2021-09-29 [1] Github (yihui/xfun@74c2a66) ## yaml 2.2.1 2020-02-01 [1] RSPM (R 4.0.3) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
