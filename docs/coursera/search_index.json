[["index.html", "Reproducibility in Cancer Informatics About this Course", " Reproducibility in Cancer Informatics October, 2021 About this Course This course is part of a series of courses for the Informatics Technology for Cancer Research (ITCR) called the Informatics Technology for Cancer Research Education Resource. This material was created by the ITCR Training Network (ITN) which is a collaborative effort of researchers around the United States to support cancer informatics and data science training through resources, technology, and events. This initiative is funded by the following grant: National Cancer Institute (NCI) UE5 CA254170. Our courses feature tools developed by ITCR Investigators and make it easier for principal investigators, scientists, and analysts to integrate cancer informatics into their workflows. Please see our website at www.itcrtraining.org for more information. "],["introduction.html", "Chapter 1 Introduction 1.1 Motivation 1.2 Target Audience 1.3 Curriculum", " Chapter 1 Introduction 1.1 Motivation Cancer datasets are plentiful, complicated, and hold untold amounts of information regarding cancer biology. Cancer researchers are working to apply their expertise to the analysis of these vast amounts of data but training opportunities to properly equip them in these efforts can be sparse. This includes training in reproducible data analysis methods. Data analyses are also are generally not reproducible without direct contact with the original researchers and a substantial amount of time and effort (BeaulieuJones2017 and Greene 2017). Reproducibility in cancer informatics (as with other fields) is still not monitored or incentivized despite that it is fundamental to the scientific method. Despite the lack of incentive, many researchers strive for reproducibility in their own work but often lack the skills or training to do so effectively. Equipping researchers with the skills to create reproducible data analyses increases the efficiency of everyone involved. Reproducible analyses are more likely to understood, applied, and replicated by others. This helps expedite the scientific process by helping researchers avoid false positive dead ends. Open source clarity in reproducible methods also saves researchers’ time so they don’t have to reinvent the proverbial wheel for methods that everyone in the field is already performing. This course introduces the concepts of reproducibility and replicability in the context of cancer informatics. It uses hands-on exercises to demonstrate in practical terms how to increase the reproducibility of data analyses. The course also introduces tools relevant to reproducibility including analysis notebooks, Docker images, git and GitHub. 1.2 Target Audience The course is intended for students in the biomedical sciences and researchers who use informatics tools in their research. 1.3 Curriculum The course includes a hands-on exercises for how to apply reproducible code concepts to their code. Individuals who take this course are encouraged to complete these activities as they follow along with the course material to help increase the reproducibility of their analyses. References "],["defining-reproducibility.html", "Chapter 2 Defining reproducibility 2.1 Learning Objectives 2.2 What is reproducibility 2.3 Reproducibility in daily life 2.4 Reproducibility is worth the effort! 2.5 Reproducibility exists on a continuum!", " Chapter 2 Defining reproducibility 2.1 Learning Objectives 2.2 What is reproducibility There’s been a lot of discussion about what is included in the term reproducibility and there is some discrepancy between fields. For the purposes of informatics and data analysis, a reproducible analysis is one that can be re-run by a different researcher and the same result and conclusion is found. Reproducibility is related to repeatability and replicability but it is worth taking the time parse out these terms. Perhaps you are like Ruby and have just found an interesting pattern through your data analysis! This has probably been the result of many months or years on your project and its worth celebrating! But before you get too excited, Ruby should ask herself whether she is able to re-run her own analysis and get the same results again. This is known as repeatability. Given that Ruby’s analysis is repeatable; she may feel confident now to share her preliminary results with her colleague, Avi the Associate. Whether or not someone else will be able to take Ruby’s code and data, re-run the analysis and obtain the same results is known as reproducibility. If Ruby’s results are able to be reproduced by Avi, now Avi may collect new data and use Ruby’s same analysis methods to analyze his data. Whether or not Avi’s new data and results concur with Ruby’s study’s original inferences is known as replicability. You may realize that these levels of research build on each other (like science is supposed to do). In this way, we can think of these in a hierarchy. Skipping any of these levels of research applicability can lead to unreliable results and conclusions. Science progresses when data and hypotheses are put through these levels thoroughly and sequentially. If results are not repeatable, they won’t be reproducible or replicable. Ideally all analyses and results would be reproducible without too much time effort spent; this would aid in the efficiency of research getting to the next stages and questions. But unfortunately, in practice, reproducibility is not as commonplace as we would hope. Institutions and reward systems generally do not prioritize or even measure reproducibility standards in research and training opportunities for reproducible techniques can be scarce. Reproducible research can often feel like uphill battle that is made steeper by lack of training opportunities. In this course, we hope to equip your research with the tools you need to enhance the reproducibility of your analyses so this uphill battle is less steep. 2.3 Reproducibility in daily life What does reproducibility in mean in the daily life of a researcher? Let’s say Ruby’s results are repeatable in her own hands and she excitedly tells her associate, Avi about her preliminary findings. Avi is very excited about these results as well as Ruby’s methods! Avi is also interested in Ruby’s analysis methods and results. So Ruby sends Avi the code and data she used to obtain the results. Now, whether or not Avi is able to obtain the same exact results with this same data and same analysis code will indicate if Ruby’s analysis is reproducible. Ruby may have spent a lot of time on her code and getting it to work on her computer, but whether it will successfully work on Avi’s computer is another story. Often when researchers share their analysis code it leads to a substantial amount of effort on the part of the researcher who has received the code to get it working and this often cannot be done successfully without help from the original code author (BeaulieuJones2017 and Greene 2017). Avi is encountering errors because Ruby’s code was written with Ruby’s computer and local set up in mind and she didn’t know how to make it more generally applicable. Avi is spending a lot of time just trying to re-run Ruby’s same analysis on her same data; he has yet to be able to try the code on any additional data (which will likely bring up even more errors). Avi is still struggling to work with Ruby’s code and is confused about the goals and approaches the code is taking. After struggling with Avi’s code for an untold amount of time, Avi may decide its time to email Ruby to get some clarity. Now both Avi and Ruby are confused about why this analysis isn’t nicely re-running for Avi. Their attempts to communicate about the code through email haven’t helped them clarify anything. Multiple versions of the code may have been sent back and forth between them and now things are taking a lot more time than either of them expected. Perhaps at some point Avi is able to successfully run Ruby’s code on Ruby’s same data. Just because Avi didn’t get any errors doesn’t mean that the code ran exactly the same as it did for Ruby. Lack of errors also doesn’t mean that either Ruby or Avi’s runs of the code ran with high accuracy or that the results can be trusted. Even a small difference in decimal point may indicate a more fundamental difference in how the analysis was performed and this could be due to differences in software versions, settings, or any number of items in their computing environments. 2.4 Reproducibility is worth the effort! Perhaps you’ve found yourself in a situation like Ruby and Avi; struggling to re-run code that you thought for sure was working a minute ago. In the upcoming chapters, we will discuss how to bolster your projects’ reproducibility. As you apply these reproducible techniques to your research may feel like it is taking more time to reach endpoints, but keep in mind that reproducible analyses and projects have higher upfront costs but these will absolutely pay off in the long term. Reproducibility in your analyses is not only a time saver for yourself, but also your colleagues, your field, and your future self! You might not change a single character in your code but then return to it in a a few days/months/years and find that it no longer runs! Reproducible code stands the test of time longer, making future you glad you spent the time to work on it. It’s said that your closest collaborator is you from 6 months ago but you don’t reply to email. Broman (n.d.) Many a data scientist has referred to their frustration with their past selves: Dear past-Hadley: PLEASE COMMENT YOUR CODE BETTER. Love present-Hadley — Hadley Wickham (@hadleywickham) April 7, 2016 The more you comment your code, and make it clear and readable, your future self will thank you. Reproducible code also saves your colleagues time! The more reproducible your code is, the less time all of your collaborators will need to spend troubleshooting it. The more people who use your code and need to try to fix it, the more time is wasted. This can add up to a lot of wasted researcher time and effort. But, reproducible code saves everyone exponential amounts of time and effort! It will also motivate individuals to use and cite your code and analyses in the future! 2.5 Reproducibility exists on a continuum! Incremental work on your analyses is good! You do not need to make your analyses perfect on the first try or even in a particular time frame. The first step in creating an analysis is to get it to work once! But the work does not end there. Furthermore, no analysis is or will ever be perfect in that it will not be reproducible in every single context throughout time. But somewhere toward the right of this continuum is what we will aim for. References "],["how-to-use-the-example-project-files.html", "Chapter 3 How to use the example project files 3.1 Downloading the chapter files", " Chapter 3 How to use the example project files Each chapter has a set of example project files for you to practice applying the reproducibility concepts we discuss. These project files will start out as not very reproducible (they don’t run properly) but at the end of the course your goal is to make them into a lovely project that creates a nice heatmap! These files come in Python or R options depending on your preference your resulting heatmap should look like one of these: This is the R version of the heatmap: This is the Python version of the heatmap: 3.1 Downloading the chapter files At the exercise portion of each chapter, we will prompt you to follow either the R or Python exercise. There is no need to do both, they are largely the same. You will download either the R or Python project files and edit the files along with the course according to the prompts. These example project files will be zipped up and you will need to unzip them before you can complete the exercise. On most operating systems, you will be able to double click your chapter zip file to unzip, but for Windows you may have to follow these instructions). Please let us know with the feedback form if you encounter any problems along the way while completing the exercises. We will have the download commands typed out for you that you will copy and paste to your command line but these are collapsed and “point and click” instructions are also provided where possible. If you are interested in using the command line but are not sure how to find it, read this article. But if you are more comfortable with “point and click” by all means follow those instructions. We hope you find this course useful and informative (and maybe even fun!). "],["organizing-your-project.html", "Chapter 4 Organizing your project 4.1 Learning Objectives 4.2 Organizational strategies 4.3 Readings about organizational strategies for data science projects: 4.4 Exercise: Organize your project!", " Chapter 4 Organizing your project 4.1 Learning Objectives Keeping your files organized is a skill that has a high long-term pay off. As you are in the thick of an analysis, you may underestimate how many files and terms you have floating around. But a short time later, you may return to your files and realize your organization was not as clear as you hoped. Tayo (2019) discusses four particular reasons why it is important to organize your project: Organization increases productivity. If a project is well organized, with everything placed in one directory, it makes it easier to avoid wasting time searching for project files such as datasets, codes, output files, and so on. A well-organized project helps you to keep and maintain a record of your ongoing and completed data science projects. Completed data science projects could be used for building future models. If you have to solve a similar problem in the future, you can use the same code with slight modifications. A well-organized project can easily be understood by other data science professionals when shared on platforms such as Github. Organization is yet another aspect of reproducibility that saves you and your colleagues time! 4.2 Organizational strategies There’s a lot of ways to keep your files organized, and there’s not a “one size fits all” organizational solution (Shapiro et al. 2021). In this chapter, we will discuss some generalities but as far as specifics we will point you to others’ who have written about works for them and advise that you use them as inspiration to figure out a strategy that works for you and your team. The most important aspects of your project organization scheme is that it: Is project-oriented (Bryan 2017). Follows consistent patterns. Is easy for you and others to find the files you need quickly. Minimizes the likelihood for errors (like writing over files accidentally). Is something maintainable! (Shapiro et al. 2021) 4.2.1 Tips for organizing your project: Getting more specific, here’s some ideas of how to organize your project: Make file names informative to those who don’t have knowledge of the project but avoid using spaces, quotes, or unusual characters in your filenames and folders – these only serve to make reading in files a nightmare in some programs. Number scripts in the order that they are run. Keep like-files together in their own directory: results tables with other results tables, etc. Including most importantly keeping raw data separate from processed data or other results! Put source scripts and functions in their own directory. Things that should never need to be called directly by yourself or anyone else. Put output in its own directories like results and plots. Have a central document (like a README) that describes the basic information about the analysis and how to re-run it. Make it easy on yourself, dates aren’t necessary. The computer keeps track of those. Make a central script that re-runs everything – including the creation of the folders! (more on this in a later chapter) Let’s see what these principles might look like put into practice. 4.2.1.1 Example organizational scheme Here’s an example of what this might look like: project-name/ ├── run_analysis.sh # Central script that runs everything again ├── 00-download-data.sh # The script that needs to be run first and is called by run_analysis.sh ├── 01-make-heatmap.Rmd # The script that needs to be run second and is also called by run_analysis.sh ├── README.md # The document that has the information that will orient someone to this project ├── plots/ # A folder of plots and resulting images │ └── project-name-heatmap.png ├── results/ # A folder results │ └── top_gene_results.tsv ├── raw-data/ # data files as they first arrive and **nothing** has been done to them yet. │ ├── project-name-raw.tsv │ └── project-name-metadata.tsv ├── processed-data/ # data that has been modified from the raw in some way. │ ├── project-name-quantile-normalized.tsv └── util/ # A folder of utilities that never needs to be called or touched directly unless troubleshooting something ├── plotting-functions.R └── data-wrangling-functions.R 4.3 Readings about organizational strategies for data science projects: But you don’t have to take my organizational strategy, there are lots of ideas out there. You can read through some of these articles to think about what kind of organizational strategy might work for you and your team: Jenny Bryan’s organizational strategy (Bryan and Hester, n.d.). Jenny Bryan on Project-oriented workflows(Bryan 2017). Data Carpentry mini-course about organizing projects (“Project Organization and Management for Genomics” n.d.). Andrew Severin’s strategy for organization (Severin n.d.). A BioStars thread where many individuals share their own organizational strategies (“How Do You Manage Your Files &amp; Directories for Your Projects?” n.d.). Data Carpentry course chapter about getting organized (“Introduction to the Command Line for Genomics” n.d.). 4.4 Exercise: Organize your project! 4.4.0.1 Get the example project files for this chapter For this chapter, we will organize our example project files! About command line If you decide to follow the command line prompts but are not familiar with it read this article. Make sure you have wget installed on your computer. You can check if you have it by running the following in your command line: wget -V ## GNU Wget 1.20.3 built on linux-gnu. ## ## -cares +digest -gpgme +https +ipv6 +iri +large-file -metalink +nls ## +ntlm +opie +psl +ssl/openssl ## ## Wgetrc: ## /etc/wgetrc (system) ## Locale: ## /usr/share/locale ## Compile: ## gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC=&quot;/etc/wgetrc&quot; ## -DLOCALEDIR=&quot;/usr/share/locale&quot; -I. -I../../src -I../lib ## -I../../lib -Wdate-time -D_FORTIFY_SOURCE=2 -DHAVE_LIBSSL -DNDEBUG ## -g -O2 -fdebug-prefix-map=/build/wget-OYIfr9/wget-1.20.3=. ## -fstack-protector-strong -Wformat -Werror=format-security ## -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall ## Link: ## gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 ## -fdebug-prefix-map=/build/wget-OYIfr9/wget-1.20.3=. ## -fstack-protector-strong -Wformat -Werror=format-security ## -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall -Wl,-Bsymbolic-functions ## -Wl,-z,relro -Wl,-z,now -lpcre2-8 -luuid -lidn2 -lssl -lcrypto -lz ## -lpsl ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a ## ## Copyright (C) 2015 Free Software Foundation, Inc. ## License GPLv3+: GNU GPL version 3 or later ## &lt;http://www.gnu.org/licenses/gpl.html&gt;. ## This is free software: you are free to change and redistribute it. ## There is NO WARRANTY, to the extent permitted by law. ## ## Originally written by Hrvoje Niksic &lt;hniksic@xemacs.org&gt;. ## Please send bug reports and questions to &lt;bug-wget@gnu.org&gt;. If this prints back something similar to this message above, then you already have wget and don’t need to do anything! But if this command prints back wget command not found you will need to install wget. Now choose which version of the example you would like to work with and follow the instructions. Python version of the exercise To get the Python project example files, click this link. Or you can use these commands in command line. mkdir -p chapter-zips wget -O chapter-zips/python-heatmap-chapt-4.zip https://raw.githubusercontent.com/jhudsl/Reproducibility-Examples/main/chapter-zips/python-heatmap-chapt-4.zip Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). Now let’s take a look at the files inside these projects. These are purposely not organized because for this exercise we will organize them! ## aggregated_metadata.json ## aml_heatmap.png ## analysis_OLD.py ## analysis.py ## dataset.zip ## LICENSE.TXT ## metadata_SRP070849.tsv ## SRP070849.tsv Organize these files! For now we will organize these files by hand, but in the upcoming chapters we will make it so our analysis places these items in the correct directories (and creates the directories if they do not exist!). Create a plots, results, and data folder and organize the files into their respective folders. Note that aggregated_metadata.json and LICENSE.TXT also belong in the `data folder. Delete any files that say “OLD”. Keeping multiple versions of your scripts around is a recipe for mistakes and confusion. In the advanced course we will discuss how to use version control to help you track this more elegantly. R version of the exercise To get the R project examples files click this link. Or you can use these commands in command line. mkdir -p chapter-zips wget -O chapter-zips/r-heatmap-chapt-4.zip https://raw.githubusercontent.com/jhudsl/Reproducibility-Examples/main/chapter-zips/r-heatmap-chapt-4.zip Now double click your chapter zip file to unzip. For Windows you may have to follow these instructions). Now let’s take a look at the files inside these projects. These are purposely not organized because for this exercise we will organize them! ## heatmap_up_to_date_OLD.R ## heatmap_up_to_date.R ## LICENSE.TXT ## metadata_SRP070849.tsv ## SRP070849.tsv Organize these files! For now we will organize these files by hand, but in the upcoming chapters we will make it so our analysis places these items in the correct directories (and creates the directories if they do not exist!). Create a plots, results, and data folder and organize the files into their respective folders. Note that aggregated_metadata.json and LICENSE.TXT also belong in the data folder. Delete any files that say “OLD”. Keeping multiple versions of your scripts around is a recipe for mistakes and confusion. In the advanced course we will discuss how to use version control to help you track this more elegantly. After your files are organized, you are ready to move on to the next chapter and start diving into the code! References "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Lead Content Instructor(s) Candace Savonen Lecturer(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved Delivered the course in some way - video or audio Content Author(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved If any other authors besides lead instructor Content Contributor(s) (include section name/link in parentheses) - make new line if more than one section involved Wrote less than a chapter Content Editor(s)/Reviewer(s) Checked your content Content Director(s) Helped guide the content direction Content Consultants (include chapter name/link in parentheses or word “General”) - make new line if more than one chapter involved Gave high level advice on content Acknowledgments Gave small assistance to content but not to the level of consulting Production Content Publisher Ira Gooding Content Publishing Reviewer(s) Reviewed overall content and aesthetics on publishing platform Technical Course Publishing Engineer(s) Helped with the code for the technical aspects related to the specific course generation Template Publishing Engineers Candace Savonen, Carrie Wright Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (Leanbuild) John Muschelli, Candace Savonen, Carrie Wright Art and Design Illustrator(s) Created graphics for the course Figure Artist(s) Created figures/plots for course Videographer(s) Filmed videos Videography Editor(s) Edited film Audiographer(s) Recorded audio Audiography Editor(s) Edited audio recordings Funding Funder(s) Institution/individual who funded course including grant number Funding Staff Staff members who help with funding   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os Ubuntu 20.04.2 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2021-10-15 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] RSPM (R 4.0.3) ## backports 1.1.10 2020-09-15 [1] RSPM (R 4.0.2) ## bookdown 0.24 2021-09-29 [1] Github (rstudio/bookdown@88bc4ea) ## callr 3.4.4 2020-09-07 [1] RSPM (R 4.0.2) ## cli 2.0.2 2020-02-28 [1] RSPM (R 4.0.0) ## crayon 1.3.4 2017-09-16 [1] RSPM (R 4.0.0) ## desc 1.2.0 2018-05-01 [1] RSPM (R 4.0.3) ## devtools 2.3.2 2020-09-18 [1] RSPM (R 4.0.3) ## digest 0.6.25 2020-02-23 [1] RSPM (R 4.0.0) ## ellipsis 0.3.1 2020-05-15 [1] RSPM (R 4.0.3) ## evaluate 0.14 2019-05-28 [1] RSPM (R 4.0.3) ## fansi 0.4.1 2020-01-08 [1] RSPM (R 4.0.0) ## fs 1.5.0 2020-07-31 [1] RSPM (R 4.0.3) ## glue 1.4.2 2020-08-27 [1] RSPM (R 4.0.3) ## hms 0.5.3 2020-01-08 [1] RSPM (R 4.0.0) ## htmltools 0.5.0 2020-06-16 [1] RSPM (R 4.0.1) ## jquerylib 0.1.1 2020-04-30 [1] RSPM (R 4.0.0) ## knitr 1.33 2021-09-29 [1] Github (yihui/knitr@a1052d1) ## leanbuild 0.1.2 2021-09-29 [1] Github (jhudsl/leanbuild@dc8f933) ## lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.0.2) ## magrittr 1.5 2014-11-22 [1] RSPM (R 4.0.0) ## memoise 1.1.0 2017-04-21 [1] RSPM (R 4.0.0) ## pillar 1.4.6 2020-07-10 [1] RSPM (R 4.0.2) ## pkgbuild 1.1.0 2020-07-13 [1] RSPM (R 4.0.2) ## pkgconfig 2.0.3 2019-09-22 [1] RSPM (R 4.0.3) ## pkgload 1.1.0 2020-05-29 [1] RSPM (R 4.0.3) ## prettyunits 1.1.1 2020-01-24 [1] RSPM (R 4.0.3) ## processx 3.4.4 2020-09-03 [1] RSPM (R 4.0.2) ## ps 1.3.4 2020-08-11 [1] RSPM (R 4.0.2) ## purrr 0.3.4 2020-04-17 [1] RSPM (R 4.0.3) ## R6 2.4.1 2019-11-12 [1] RSPM (R 4.0.0) ## readr 1.4.0 2020-10-05 [1] RSPM (R 4.0.2) ## remotes 2.2.0 2020-07-21 [1] RSPM (R 4.0.3) ## rlang 0.4.10 2021-09-29 [1] Github (r-lib/rlang@f0c9be5) ## rmarkdown 2.10 2021-09-29 [1] Github (rstudio/rmarkdown@02d3c25) ## rprojroot 1.3-2 2018-01-03 [1] RSPM (R 4.0.0) ## sessioninfo 1.1.1 2018-11-05 [1] RSPM (R 4.0.3) ## stringi 1.5.3 2020-09-09 [1] RSPM (R 4.0.3) ## stringr 1.4.0 2019-02-10 [1] RSPM (R 4.0.3) ## testthat 3.0.1 2021-09-29 [1] Github (R-lib/testthat@e99155a) ## tibble 3.0.3 2020-07-10 [1] RSPM (R 4.0.2) ## usethis 2.0.1.9000 2021-09-29 [1] Github (r-lib/usethis@3398055) ## vctrs 0.3.4 2020-08-29 [1] RSPM (R 4.0.2) ## withr 2.3.0 2020-09-22 [1] RSPM (R 4.0.2) ## xfun 0.26 2021-09-29 [1] Github (yihui/xfun@74c2a66) ## yaml 2.2.1 2020-02-01 [1] RSPM (R 4.0.3) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
